# assistant.py
import subprocess
import torch
import os
import time
from datetime import datetime
from pathlib import Path
from openvoice.api import ToneColorConverter
from melo.api import TTS as MeloTTS
from llama_index.core import load_index_from_storage, StorageContext
from llama_index.llms.ollama import Ollama
from llama_index.core import Settings

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ===
WHISPER_PATH = os.path.expanduser("~/father_ai/whisper.cpp/main")
WHISPER_MODEL = os.path.expanduser("~/father_ai/whisper.cpp/models/ggml-small.bin")
FATHER_EMB = os.path.expanduser("~/father_ai/speaker_embeddings/father.npy")
INDEX_DIR = os.path.expanduser("~/father_ai/father_index")
OUTPUT_WAV = "response.wav"
RECORD_WAV = "query.wav"
LOGS_DIR = os.path.expanduser("~/father_ai/logs")

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏
Path(LOGS_DIR).mkdir(parents=True, exist_ok=True)

# === –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ===
last_interaction = 0
current_log = None

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π ===
device = "cuda:0" if torch.cuda.is_available() else "cpu"

# OpenVoice
converter = ToneColorConverter('checkpoints/converter/config.json', device=device)
converter.load_ckpt('checkpoints/converter/checkpoint.pth')
father_emb = torch.load(FATHER_EMB, map_location=device)

# MeloTTS –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ
melo_tts = MeloTTS(language='RU', device=device)

# LLM
llm = Ollama(model="llama3")
Settings.llm = llm
storage_context = StorageContext.from_defaults(persist_dir=INDEX_DIR)
index = load_index_from_storage(storage_context)
chat_engine = index.as_chat_engine(chat_mode="condense_question", verbose=False)

# === –§—É–Ω–∫—Ü–∏–∏ ===
def get_log_file():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–∞ —Ç–µ–∫—É—â–µ–π –¥–∞—Ç—ã"""
    today = datetime.now().strftime("%Y-%m-%d")
    return os.path.join(LOGS_DIR, f"dialog_{today}.txt")

def log_message(speaker, text):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –ª–æ–≥-—Ñ–∞–π–ª —Å –∫—Ä–∞—Å–∏–≤—ã–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    global current_log
    if current_log is None:
        current_log = get_log_file()
        if not os.path.exists(current_log):
            with open(current_log, 'w', encoding='utf-8') as f:
                f.write(f"üìÖ –î–∏–∞–ª–æ–≥ —Å —Ü–∏—Ñ—Ä–æ–≤—ã–º –¥–≤–æ–π–Ω–∏–∫–æ–º –æ—Ç—Ü–∞\n")
                f.write(f"üóìÔ∏è –î–∞—Ç–∞: {datetime.now().strftime('%d %B %Y')}\n")
                f.write("="*60 + "\n\n")
    
    timestamp = datetime.now().strftime("%H:%M:%S")
    with open(current_log, 'a', encoding='utf-8') as f:
        f.write(f"[{timestamp}] {speaker}: {text}\n")
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {os.path.basename(current_log)}")

def record_audio(duration=5):
    subprocess.run(["arecord", "-f", "S16_LE", "-r", "16000", "-c", "1", "-d", str(duration), RECORD_WAV], 
                   stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

def speech_to_text():
    result = subprocess.run([WHISPER_PATH, "-m", WHISPER_MODEL, "-f", RECORD_WAV, "-l", "ru"], 
                            capture_output=True, text=True)
    return result.stdout.strip()

def generate_response(text):
    return chat_engine.chat(text).response

def text_to_speech(text, output_path):
    tmp_path = "tmp_base.wav"
    melo_tts.tts_to_file(text, melo_tts.hps.data.spk2id['[RU]'], tmp_path)
    converter.convert(audio_src_path=tmp_path, src_se=None, tgt_se=father_emb, output_path=output_path)

def play_audio(file_path):
    subprocess.run(["aplay", file_path], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

# === –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª ===
if __name__ == "__main__":
    print("üéôÔ∏è –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞. –ì–æ–≤–æ—Ä–∏—Ç–µ (5 —Å–µ–∫—É–Ω–¥ –∑–∞–ø–∏—Å–∏)...")
    try:
        while True:
            record_audio()
            text = speech_to_text()
            if not text.strip():
                continue
                
            print(f"\nüë§ –í—ã: {text}")
            log_message("–ù–∏–∫–∏—Ç–∞", text)
            
            if "–≤—ã—Ö–æ–¥" in text.lower() or "–ø–æ–∫–∞" in text.lower():
                goodbye = "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è, —Å—ã–Ω. –ë–µ—Ä–µ–≥–∏ —Å–µ–±—è."
                print(f"üë® –û—Ç–µ—Ü: {goodbye}")
                log_message("–û—Ç–µ—Ü", goodbye)
                text_to_speech(goodbye, OUTPUT_WAV)
                play_audio(OUTPUT_WAV)
                break
                
            response = generate_response(text)
            print(f"üë® –û—Ç–µ—Ü: {response}")
            log_message("–û—Ç–µ—Ü", response)
            text_to_speech(response, OUTPUT_WAV)
            play_audio(OUTPUT_WAV)
            
            last_interaction = time.time()
            
    except KeyboardInterrupt:
        print("\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
